{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from box import Box\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_bert import BertLearner, BertDataBunch, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "run_start_time = datetime.today().strftime('%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"../sample_data/imdb_movie_reviews\")\n",
    "DATA_PATH = PATH/'data'\n",
    "LABEL_PATH = PATH/'label'\n",
    "OUT_PATH = PATH/'.output'\n",
    "OUT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "MODEL_PATH=OUT_PATH/'model'\n",
    "MODEL_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "LOG_PATH = OUT_PATH/'logs/'\n",
    "LOG_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Box({\n",
    "    \"run_text\": \"ibdm_reviews\",\n",
    "    \"max_seq_length\": 512,\n",
    "    \"batch_size\": 8,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"num_train_epochs\": 6,\n",
    "    \"fp16\": False,\n",
    "    \"model_name\": 'albert-base-v2',\n",
    "    \"model_type\": 'albert'\n",
    "})\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.device_count() else torch.device('cpu')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    args.multi_gpu = True\n",
    "else:\n",
    "    args.multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = str(LOG_PATH/'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(logfile),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14/2019 08:19:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model from cache at /Users/kaushaltrivedi/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n",
      "12/14/2019 08:19:40 - INFO - root -   Loading features from cached file ../sample_data/imdb_movie_reviews/data/cache/cached_albert_train_multi_class_512_train_sample.csv\n",
      "12/14/2019 08:19:40 - INFO - root -   Loading features from cached file ../sample_data/imdb_movie_reviews/data/cache/cached_albert_dev_multi_class_512_val_sample.csv\n"
     ]
    }
   ],
   "source": [
    "databunch = BertDataBunch(DATA_PATH, LABEL_PATH, args.model_name, \n",
    "                          train_file=\"train_sample.csv\", val_file=\"val_sample.csv\",\n",
    "                          batch_size_per_gpu=args.batch_size, \n",
    "                          max_seq_length=args.max_seq_length, \n",
    "                          multi_gpu=args.multi_gpu,\n",
    "                          multi_label=False,\n",
    "                          model_type=args.model_type\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [{\"name\": \"accuracy\", \"function\": accuracy}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14/2019 08:19:41 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json from cache at /Users/kaushaltrivedi/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.ea38adf566af403b92e06f53ac1b443ebd324162fc74a90de95609963d429505\n",
      "12/14/2019 08:19:41 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "12/14/2019 08:19:41 - WARNING - transformers.modeling_utils -   There is currently an upstream reproducibility issue with ALBERT v2 models. Please see https://github.com/google-research/google-research/issues/119 for more information.\n",
      "12/14/2019 08:19:42 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin from cache at /Users/kaushaltrivedi/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
      "12/14/2019 08:19:43 - INFO - transformers.modeling_utils -   Weights of AlbertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "12/14/2019 08:19:43 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n"
     ]
    }
   ],
   "source": [
    "learner = BertLearner.from_pretrained_model(databunch, args.model_name, metrics=metrics, \n",
    "                                            device=device, multi_gpu=args.multi_gpu, is_fp16=args.fp16,\n",
    "                                            multi_label=False, logging_steps=0,\n",
    "                                            output_dir=OUT_PATH, logger=logger\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../sample_data/imdb_movie_reviews/.output/tensorboard\n",
      "12/14/2019 08:19:43 - INFO - root -   ***** Running training *****\n",
      "12/14/2019 08:19:43 - INFO - root -     Num examples = 100\n",
      "12/14/2019 08:19:43 - INFO - root -     Num Epochs = 2\n",
      "12/14/2019 08:19:43 - INFO - root -     Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "12/14/2019 08:19:43 - INFO - root -     Gradient Accumulation steps = 1\n",
      "12/14/2019 08:19:43 - INFO - root -     Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14/2019 08:25:30 - INFO - root -   Running evaluation\n",
      "12/14/2019 08:25:30 - INFO - root -     Num examples = 50\n",
      "12/14/2019 08:25:30 - INFO - root -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='4', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4/4 01:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14/2019 08:26:31 - INFO - root -   eval_loss after epoch 1: 0.8099662363529205: \n",
      "12/14/2019 08:26:31 - INFO - root -   eval_accuracy after epoch 1: 0.36: \n",
      "12/14/2019 08:26:31 - INFO - root -   lr after epoch 1: 2.5e-05\n",
      "12/14/2019 08:26:31 - INFO - root -   train_loss after epoch 1: 0.7384268320523776\n",
      "12/14/2019 08:26:31 - INFO - root -   \n",
      "\n",
      "12/14/2019 08:32:17 - INFO - root -   Running evaluation\n",
      "12/14/2019 08:32:17 - INFO - root -     Num examples = 50\n",
      "12/14/2019 08:32:17 - INFO - root -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='4', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4/4 00:59<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14/2019 08:33:16 - INFO - root -   eval_loss after epoch 2: 0.8012044578790665: \n",
      "12/14/2019 08:33:16 - INFO - root -   eval_accuracy after epoch 2: 0.36: \n",
      "12/14/2019 08:33:16 - INFO - root -   lr after epoch 2: 0.0\n",
      "12/14/2019 08:33:16 - INFO - root -   train_loss after epoch 2: 0.7632057254131024\n",
      "12/14/2019 08:33:16 - INFO - root -   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26, 0.7508162787327399)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(2, args.learning_rate, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14/2019 08:33:16 - INFO - transformers.configuration_utils -   Configuration saved in ../sample_data/imdb_movie_reviews/.output/model_out/config.json\n",
      "12/14/2019 08:33:16 - INFO - transformers.modeling_utils -   Model weights saved in ../sample_data/imdb_movie_reviews/.output/model_out/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "learner.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_bert.prediction import BertClassificationPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14/2019 08:51:34 - INFO - transformers.tokenization_utils -   Model name '../sample_data/imdb_movie_reviews/.output/model_out' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming '../sample_data/imdb_movie_reviews/.output/model_out' is a path or url to a directory containing tokenizer files.\n",
      "12/14/2019 08:51:34 - INFO - transformers.tokenization_utils -   loading file ../sample_data/imdb_movie_reviews/.output/model_out/spiece.model\n",
      "12/14/2019 08:51:34 - INFO - transformers.tokenization_utils -   loading file ../sample_data/imdb_movie_reviews/.output/model_out/added_tokens.json\n",
      "12/14/2019 08:51:34 - INFO - transformers.tokenization_utils -   loading file ../sample_data/imdb_movie_reviews/.output/model_out/special_tokens_map.json\n",
      "12/14/2019 08:51:34 - INFO - transformers.tokenization_utils -   loading file ../sample_data/imdb_movie_reviews/.output/model_out/tokenizer_config.json\n",
      "12/14/2019 08:51:34 - INFO - transformers.configuration_utils -   loading configuration file ../sample_data/imdb_movie_reviews/.output/model_out/config.json\n",
      "12/14/2019 08:51:34 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "12/14/2019 08:51:34 - INFO - transformers.modeling_utils -   loading weights file ../sample_data/imdb_movie_reviews/.output/model_out/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "predictor = BertClassificationPredictor(OUT_PATH/'model_out', LABEL_PATH, multi_label=False, model_type=args.model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14/2019 12:52:36 - INFO - root -   Writing example 0 of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('1', 0.6604397296905518), ('0', 0.33956027030944824)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_batch([\"i like you\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
